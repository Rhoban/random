# Rhoban Random

A library allowing to sample classical distributions more easily but also
allowing to measure the probability density function for basic distributions.


## Gaussian mixture model

This library uses `OpenCV` implementation of the Expectation-Maximization
algorithm to build Gaussian Mixture Models from data. By using the Bayesian
Information Criterion (BIC), it can automatically choose an approriate number of
clusters.

Results can be compared with python `sklearn` implementation to ensure
implementation is correct. The different tools are as follows:

- `examples/generate_gmm_samples.cpp`: A tool allowing to produce samples in a
  `csv` file based on a `gaussian mixture model` described in a `json` file. An
  example of `json` file can be found in `configs/gmm.json`.
- `examples/expectation_maximization.cpp`: A tool allowing to compare the effect
  of different numbers of gaussians and different types of parametrization on both
  BIC and AIC. It takes as input a set of points in a `csv` file (which can be
  generated by `generate_gmm_samples`)
  - Creates the following files:
    - `results.csv`: contains the scores of all the different configurations tested
    - `best_aic.json`: best GMM based on AIC criterion
    - `best_bic.json`: best GMM based on BIC criterion
  - Visualization is ensured by the following scripts:
    - `scripts/plot_em_scores.r`: Allows to visualize score depending on the type
      of covariance matrix and number of clusters
    - `scripts/plot_gmm.r`: Draws the confidence ellipse for a gaussian mixture
      model. Can also draw the samples used to infer the GMM if provided. Is only
      functional for 2 dimensional data sets.
- `external/gmm.py`: An `sklearn` based implementation modified to take a `csv`
  file as input.
